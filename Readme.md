# Distributed SAC

### Getting Started

You can run this repository as follows:

**[Important] Before running, you should set your own ray parameters that fit your computer in respective `main.py`.**

Choose one of these.

1. To run `LunarLander_Distributed_SAC`, `python3 LunarLander_Distributed_SAC/src/main.py`
2. To run `MT1_Distributed_VSAC`, `python3 MT1_Distributed_VSAC/src/main.py`
3. To run `MT1_Distributed_CARE`, `python3 MT1_Distributed_CARE/src/main.py`
4. To run `MT10_Distributed_MTSAC`, `python3 MT10_Distributed_MTSAC/src/main.py`
5. To run `MT10_Distributed_CARE`, `python3 MT10_Distributed_CARE/src/main.py`

### Reference papers

1. [Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor](https://arxiv.org/abs/1801.01290)
2. [Soft Actor-Critic Algorithms and Applications](https://arxiv.org/abs/1812.05905)
3. [Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning](https://arxiv.org/abs/1910.10897)
4. [Multi-Task Reinforcement Learning with Soft Modularization](https://arxiv.org/abs/2003.13661)
5. [Multi-Task Reinforcement Learning with Context-based Representations](https://arxiv.org/abs/2102.06177)